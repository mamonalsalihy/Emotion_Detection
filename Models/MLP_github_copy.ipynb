{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MLP_github_copy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7d2ec216fbda4a8b888e2af8ae0e7244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7b4f29eb8df1461e956f1f544820dd23",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e01fef8d67f641a580d03207d1d2d96f",
              "IPY_MODEL_4fd5876651b54d07ab00766b2e640296"
            ]
          }
        },
        "7b4f29eb8df1461e956f1f544820dd23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e01fef8d67f641a580d03207d1d2d96f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2e563553408041da926f653eda2bc210",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0345189ae85c4bddb545653b015efbc1"
          }
        },
        "4fd5876651b54d07ab00766b2e640296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dc9c3c085fce4be48e54e8db3951c5d9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/? [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b76ef8faa17c4c56b3f5c4bea98242c2"
          }
        },
        "2e563553408041da926f653eda2bc210": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0345189ae85c4bddb545653b015efbc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc9c3c085fce4be48e54e8db3951c5d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b76ef8faa17c4c56b3f5c4bea98242c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mamonalsalihy/Emotion_Detection/blob/main/Models/MLP_github_copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxwKYUNM2QNB",
        "outputId": "6935266b-fc11-493d-8d0d-a37e688a0ae7"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9W8GiIqkZLtC",
        "outputId": "f4e89a0b-5023-412a-e287-1f4e510bd21b"
      },
      "source": [
        "# loading in the dependencies\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "import os\n",
        "import pandas as pd\n",
        "import csv\n",
        "import pickle as pkl\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sea\n",
        "import re\n",
        "import os\n",
        "import spacy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import math\n",
        "from itertools import chain\n",
        "\n",
        "import gensim\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EB3IDGJJE7M"
      },
      "source": [
        "Must upload the dataset splits to session to read the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DtZFtAg7uga"
      },
      "source": [
        "test_path = './test.csv'\r\n",
        "train_path = './train.csv'\r\n",
        "valid_path = './valid.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "zbS1su3ry8nR",
        "outputId": "3c4dd4c6-d07d-4892-aae6-9c361de09316"
      },
      "source": [
        "with open(train_path, \"r\") as intrain: \n",
        "    train = pd.read_csv(intrain)\n",
        "with open(valid_path, \"r\") as indev: \n",
        "    valid = pd.read_csv(indev)\n",
        "with open(test_path, \"r\") as intest: \n",
        "    test = pd.read_csv(intest)\n",
        "print(train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-def19f4606e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mintrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mindev\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mintest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dod-Bn41htrq"
      },
      "source": [
        "train_speaker = train.loc[train[\"speaker_label\"] == \"speaker\"]\n",
        "train_listener = train.loc[train[\"speaker_label\"] == \"listener\"]\n",
        "\n",
        "valid_speaker = valid.loc[valid[\"speaker_label\"] == \"speaker\"]\n",
        "valid_listener = valid.loc[valid[\"speaker_label\"] == \"listener\"]\n",
        "\n",
        "test_speaker = test.loc[test[\"speaker_label\"] == \"speaker\"]\n",
        "test_listener = test.loc[test[\"speaker_label\"] == \"listener\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR4HI3VSwdIJ"
      },
      "source": [
        "##Feature Builder Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "545JwQedwe-a"
      },
      "source": [
        "# We'll be using SkLearn's TfIdfVectorizer to construct our n-gram feature vectors\n",
        "\n",
        "# We'll create our custom sequencer class for converting a text into a sequence of integers corresponding to our tokens\n",
        "class Sequencer(object):\n",
        "    def __init__(self, corpus, bos_token='<s>', eos_token='</s>', unk_token='<unk>', pad_token='<pad>'):\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "\n",
        "        self.unk_index = self.add_token(unk_token) \n",
        "        self.pad_index = self.add_token(pad_token)\n",
        "        self.bos_index = self.add_token(bos_token)\n",
        "        self.eos_index = self.add_token(eos_token)\n",
        "        self.nlp = spacy.load('en')\n",
        "        self.tokenizer = lambda text: [t.text for t in self.nlp(text)]\n",
        "\n",
        "    def add_token(self, token):\n",
        "\n",
        "        self.word2idx[token] = new_index = len(self.word2idx)\n",
        "        self.idx2word[new_index] = token\n",
        "\n",
        "        return new_index\n",
        "\n",
        "    def encode(self, text):\n",
        "        # Input will look like:\n",
        "        # [<s>, w1, w2, ..., wn, </s>]\n",
        "        tokens = self.tokenizer(text)\n",
        "\n",
        "        sequence = [self.bos_index]\n",
        "        for token in tokens:\n",
        "\n",
        "            index = self.word2idx.get(token, self.unk_index)\n",
        "            sequence.append(index)\n",
        "        sequence.append(self.eos_index)\n",
        "\n",
        "        return sequence\n",
        "\n",
        "    def create_padded_tensor(self, sequences):\n",
        "        # Given a list of sequences, pad all to the same length\n",
        "\n",
        "        max_seq_len = max(len(sequence) for sequence in sequences)\n",
        "        tensor = torch.full((len(sequences), max_seq_len), self.pad_index, dtype=torch.long)\n",
        "\n",
        "        for i, sequence in enumerate(sequences):\n",
        "            for j, token in enumerate(sequence):\n",
        "                tensor[i][j] = token\n",
        "        \n",
        "        return tensor\n",
        "\n",
        "# For converting labels into indices\n",
        "class LabelIndexer(object):\n",
        "    def __init__(self, labels):\n",
        "        self.label2idx = {label: i for i, label in enumerate(labels)}\n",
        "        self.idx2label = {i:label for label, i in self.label2idx.items()}\n",
        "        self.labels = labels\n",
        "\n",
        "    def encode(self, y):\n",
        "        return self.label2idx[y]\n",
        "\n",
        "    def encode_batch(self, ys):\n",
        "        return torch.LongTensor([self.encode(y) for y in ys])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMi7614Zwf7O"
      },
      "source": [
        "## Dataset class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4juajTNCxYlm"
      },
      "source": [
        "class EmpatheticDataset(Dataset):\n",
        "    def __init__(self, texts, liwc, labels, input_transformer, output_transformer):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.liwc  = liwc.values\n",
        "        self.input_transformer = input_transformer\n",
        "        self.output_transformer = output_transformer\n",
        "\n",
        "    def __getitem__(self, index): # Return a single example\n",
        "        text = self.texts[index]\n",
        "        label = self.labels[index]\n",
        "        liwc = self.liwc[index]\n",
        "        x_liwc = torch.tensor(liwc)\n",
        "        x = self.input_transformer(text)\n",
        "        y = self.output_transformer(label)       \n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqL1cJSCvksw"
      },
      "source": [
        "### MultiLayer Perceptron\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU4-LPelxufo"
      },
      "source": [
        "class MultiLayerPerceptron(nn.Module):\n",
        "    \"\"\"\n",
        "    At its simplest, a multilayer perceptron is a 2 layer network\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_size, dropout=False, dropout_p=0.1):\n",
        "        super(MultiLayerPerceptron, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size, bias=True)\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size, bias=True)\n",
        "\n",
        "        self.add_dropout = dropout\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = F.relu(self.fc1(x))\n",
        "        if self.add_dropout:\n",
        "            logits = self.fc2(self.dropout(h))\n",
        "        else:\n",
        "            logits = self.fc2(h)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb728zcXx2Nd"
      },
      "source": [
        "## Trainer Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iTOIdN2x5vv"
      },
      "source": [
        "class MultiClassTrainer(object):\n",
        "    \"\"\"\n",
        "    Trainer for training a multi-class classification model\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, optimizer, loss_fn, device=\"cpu\", log_every_n=None):\n",
        "        self.model = model.to(device)\n",
        "        self.optimizer = optimizer\n",
        "        self.device = device\n",
        "        self.loss_fn = loss_fn\n",
        "        \n",
        "        self.log_every_n = log_every_n if log_every_n else 0\n",
        "\n",
        "\n",
        "    def _print_summary(self):\n",
        "        print(self.model)\n",
        "        print(self.optimizer)\n",
        "        print(self.loss_fn)\n",
        "\n",
        "    def train(self, loader):\n",
        "        \"\"\"\n",
        "        Run a single epoch of training\n",
        "        \"\"\"\n",
        "\n",
        "        self.model.train() # Run model in training mode\n",
        "\n",
        "        loss_history = []\n",
        "        running_loss = 0.\n",
        "        running_loss_history = []\n",
        "\n",
        "        for i, batch in tqdm(enumerate(loader)):\n",
        "            batch_size = batch[0].shape[0]\n",
        "            self.optimizer.zero_grad() # Always set gradient to 0 before computing it\n",
        "\n",
        "            logits = self.model(batch[0].to(self.device)) # Forward pass, # Wx + b\n",
        "            #print(logits)\n",
        "            #print(batch[1].view(-1).to(self.device))\n",
        "            loss = self.loss_fn(logits, batch[1].view(-1).to(self.device)) # Compute loss: Cross entropy loss\n",
        "\n",
        "            loss_history.append(loss.item())\n",
        "\n",
        "            \n",
        "\n",
        "            running_loss += (loss_history[-1] - running_loss) / (i + 1) # Compute rolling average\n",
        "\n",
        "            if self.log_every_n and i % self.log_every_n == 0:\n",
        "                print(\"Running loss: \", running_loss)\n",
        "\n",
        "            running_loss_history.append(running_loss)\n",
        "\n",
        "            loss.backward() # Perform backprop, which will compute dL/dw\n",
        "\n",
        "            nn.utils.clip_grad_norm_(self.model.parameters(), 3.0)\n",
        "            self.optimizer.step() # Update step: w = w - eta * dL / dW\n",
        "\n",
        "        print(\"Epoch completed!\")\n",
        "        print(\"Epoch Loss: \", running_loss)\n",
        "        print(\"Epoch Perplexity: \", math.exp(running_loss))\n",
        "\n",
        "        # The history information can allow us to draw a loss plot\n",
        "        return loss_history, running_loss_history\n",
        "\n",
        "    def evaluate(self, loader, labels):\n",
        "        \"\"\"\n",
        "        Evaluate the model on a validation set\n",
        "        \"\"\"\n",
        "\n",
        "        self.model.eval() # Run model in eval mode (disables dropout layer)\n",
        "\n",
        "        batch_wise_true_labels = []\n",
        "        batch_wise_predictions = []\n",
        "\n",
        "        loss_history = []\n",
        "        running_loss = 0.\n",
        "        running_loss_history = []\n",
        "\n",
        "        with torch.no_grad(): # Disable gradient computation - required only during training\n",
        "            for i, batch in tqdm(enumerate(loader)):\n",
        "                # batch[0] shape: (batch_size, input_size)\n",
        "\n",
        "                logits = self.model(batch[0].to(self.device)) # Run forward pass (except we don't store gradients)\n",
        "                # logits shape: (batch_size, num_classes)\n",
        "                \n",
        "                loss = self.loss_fn(logits, batch[1].view(-1).to(self.device)) # Compute loss\n",
        "                # No backprop is done during validation\n",
        "                loss_history.append(loss.item())\n",
        "\n",
        "                running_loss += (loss_history[-1] - running_loss) / (i + 1) # Compute rolling average\n",
        "                \n",
        "                running_loss_history.append(running_loss)\n",
        "\n",
        "                # Converts the raw outputs into probabilities for each class using softmax\n",
        "                probs = F.softmax(logits, dim=-1) \n",
        "                # probs shape: (batch_size, num_classes)\n",
        "\n",
        "                predictions = torch.argmax(probs, dim=-1) # Output predictions\n",
        "                # predictions shape: (batch_size)\n",
        "\n",
        "                batch_wise_true_labels.append(batch[1].tolist())\n",
        "                batch_wise_predictions.append(predictions.tolist())\n",
        "        \n",
        "        # flatten the list of predictions using itertools\n",
        "        all_true_labels = list(chain.from_iterable(batch_wise_true_labels))\n",
        "        all_predictions = list(chain.from_iterable(batch_wise_predictions))\n",
        "\n",
        "        # Now we can generate a classification report\n",
        "        print(\"Classification report after epoch:\")\n",
        "        print(classification_report(all_true_labels, all_predictions))\n",
        "        # print(confusion_matrix(all_true_labels,all_predictions))\n",
        "        return loss_history, running_loss_history\n",
        "\n",
        "    def get_model_dict(self):\n",
        "        return self.model.state_dict()\n",
        "\n",
        "    def run_training(self, train_loader, valid_loader, labels, n_epochs=10):\n",
        "        # Useful for us to review what experiment we're running\n",
        "        # Normally, you'd want to save this to a file\n",
        "        self._print_summary()\n",
        "\n",
        "        train_losses = []\n",
        "        train_running_losses = []\n",
        "\n",
        "        valid_losses = []\n",
        "        valid_running_losses = []\n",
        "\n",
        "        for i in range(n_epochs):\n",
        "            loss_history, running_loss_history = self.train(train_loader)\n",
        "            valid_loss_history, valid_running_loss_history = self.evaluate(valid_loader, labels)\n",
        "\n",
        "            train_losses.append(loss_history)\n",
        "            train_running_losses.append(running_loss_history)\n",
        "\n",
        "            valid_losses.append(valid_loss_history)\n",
        "            valid_running_losses.append(valid_running_loss_history)\n",
        "\n",
        "        # Training done, let's look at the loss curves\n",
        "        all_train_losses = list(chain.from_iterable(train_losses))\n",
        "        all_train_running_losses = list(chain.from_iterable(train_running_losses))\n",
        "\n",
        "        all_valid_losses = list(chain.from_iterable(valid_losses))\n",
        "        all_valid_running_losses = list(chain.from_iterable(valid_running_losses))\n",
        "\n",
        "        train_epoch_idx = range(len(all_train_losses))\n",
        "        valid_epoch_idx = range(len(all_valid_losses))\n",
        "        # sns.lineplot(epoch_idx, all_losses)\n",
        "        sns.lineplot(train_epoch_idx, all_train_running_losses)\n",
        "        sns.lineplot(valid_epoch_idx, all_valid_running_losses)\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1ApvqMmyZf9"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5S8ZV6hzquO"
      },
      "source": [
        "def convert_column(dataset, column): \n",
        "   texts = [text for text in dataset[column]]\n",
        "   texts = (*texts,)\n",
        "   return texts\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMEiQ4T4Hg6N"
      },
      "source": [
        "train = train.drop_duplicates(subset=['clean_prompt'])\n",
        "valid = valid.drop_duplicates(subset=['clean_prompt'])\n",
        "#test = test.drop_duplicates(subset=['clean_prompt'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEjlHcy7-pB_"
      },
      "source": [
        "def convert_column(dataset, column): \n",
        "   texts = [text for text in dataset[column]]\n",
        "   texts = (*texts,)\n",
        "   return texts\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfvQIXRLaynC"
      },
      "source": [
        "train_liwc = train[['Total Function Words', 'Total Pronouns', 'Personal Pronouns', 'First Person Singular', 'First Person Plural', 'Second Person', 'Third Person Singular', 'Third Person Plural', ' Impersonal Pronouns', 'Articles', 'Common Verbs', 'Auxiliary Verbs', 'Past Tense', 'Present Tense', 'Future Tense', 'Adverbs', 'Prepositions', 'Conjunctions', 'Negations', 'Quantifiers', 'Number', 'Swear Words', 'Social Processes', 'Family', 'Friends', 'Humans', 'Affective Processes', 'Positive Emotion', 'Negative Emotion', 'Anxiety', 'Anger', 'Sadness', 'Cognitive Processes', 'Insight', 'Causation', 'Discrepancy', 'Tentative', 'Certainty', 'Inhibition', 'Inclusive', 'Exclusive', 'Perceptual Processes', 'See', 'Hear', 'Feel', 'Biological Processes', 'Body', 'Health', 'Sexual', 'Ingestion', 'Relativity', 'Motion', 'Space', 'Time', 'Work', 'Achievement', 'Leisure', 'Home', 'Money', 'Religion', 'Death', 'Assent', 'Nonfluencies', 'Fillers', 'Total first person', 'Total third person', 'Positive feelings', 'Optimism and energy', 'Communication', 'Other references to people', 'Up', 'Down', 'Occupation', 'School', 'Sports', 'TV', 'Music', 'Metaphysical issues', 'Physical states and functions', 'Sleeping', 'Grooming']]\n",
        "valid_liwc = valid[['Total Function Words', 'Total Pronouns', 'Personal Pronouns', 'First Person Singular', 'First Person Plural', 'Second Person', 'Third Person Singular', 'Third Person Plural', ' Impersonal Pronouns', 'Articles', 'Common Verbs', 'Auxiliary Verbs', 'Past Tense', 'Present Tense', 'Future Tense', 'Adverbs', 'Prepositions', 'Conjunctions', 'Negations', 'Quantifiers', 'Number', 'Swear Words', 'Social Processes', 'Family', 'Friends', 'Humans', 'Affective Processes', 'Positive Emotion', 'Negative Emotion', 'Anxiety', 'Anger', 'Sadness', 'Cognitive Processes', 'Insight', 'Causation', 'Discrepancy', 'Tentative', 'Certainty', 'Inhibition', 'Inclusive', 'Exclusive', 'Perceptual Processes', 'See', 'Hear', 'Feel', 'Biological Processes', 'Body', 'Health', 'Sexual', 'Ingestion', 'Relativity', 'Motion', 'Space', 'Time', 'Work', 'Achievement', 'Leisure', 'Home', 'Money', 'Religion', 'Death', 'Assent', 'Nonfluencies', 'Fillers', 'Total first person', 'Total third person', 'Positive feelings', 'Optimism and energy', 'Communication', 'Other references to people', 'Up', 'Down', 'Occupation', 'School', 'Sports', 'TV', 'Music', 'Metaphysical issues', 'Physical states and functions', 'Sleeping', 'Grooming']]\n",
        "test_liwc = test[['Total Function Words', 'Total Pronouns', 'Personal Pronouns', 'First Person Singular', 'First Person Plural', 'Second Person', 'Third Person Singular', 'Third Person Plural', ' Impersonal Pronouns', 'Articles', 'Common Verbs', 'Auxiliary Verbs', 'Past Tense', 'Present Tense', 'Future Tense', 'Adverbs', 'Prepositions', 'Conjunctions', 'Negations', 'Quantifiers', 'Number', 'Swear Words', 'Social Processes', 'Family', 'Friends', 'Humans', 'Affective Processes', 'Positive Emotion', 'Negative Emotion', 'Anxiety', 'Anger', 'Sadness', 'Cognitive Processes', 'Insight', 'Causation', 'Discrepancy', 'Tentative', 'Certainty', 'Inhibition', 'Inclusive', 'Exclusive', 'Perceptual Processes', 'See', 'Hear', 'Feel', 'Biological Processes', 'Body', 'Health', 'Sexual', 'Ingestion', 'Relativity', 'Motion', 'Space', 'Time', 'Work', 'Achievement', 'Leisure', 'Home', 'Money', 'Religion', 'Death', 'Assent', 'Nonfluencies', 'Fillers', 'Total first person', 'Total third person', 'Positive feelings', 'Optimism and energy', 'Communication', 'Other references to people', 'Up', 'Down', 'Occupation', 'School', 'Sports', 'TV', 'Music', 'Metaphysical issues', 'Physical states and functions', 'Sleeping', 'Grooming']]\n",
        "\n",
        "train_prompt = convert_column(train,'clean_prompt')\n",
        "valid_prompt = convert_column(valid,'clean_prompt')\n",
        "test_prompt = convert_column(test,'clean_prompt')\n",
        "\n",
        "train_context_labels = convert_column(train,'context')\n",
        "valid_context_labels = convert_column(valid,'context')\n",
        "test_context_labels = convert_column(test,'context')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3tCwpKqyZ0u"
      },
      "source": [
        "tfidf_vec = TfidfVectorizer()\n",
        "tfidf_vec.fit(train_prompt)\n",
        "input_transformer = lambda text: torch.FloatTensor(tfidf_vec.transform([text]).todense()).squeeze(0)\n",
        "\n",
        "label_indexer = LabelIndexer(list(set(train_context_labels +valid_context_labels)))\n",
        "output_transformer = lambda label: torch.LongTensor([label_indexer.encode(label)])\n",
        "\n",
        "train_tfidf_dataset = EmpatheticDataset(train_prompt, train_liwc, train_context_labels, input_transformer, output_transformer)\n",
        "valid_tfidf_dataset = EmpatheticDataset(valid_prompt, valid_liwc,  valid_context_labels, input_transformer, output_transformer)\n",
        "test_tfidf_dataset = EmpatheticDataset(test_prompt, test_liwc, test_context_labels, input_transformer, output_transformer)\n",
        "\n",
        "train_tfidf_loader = torch.utils.data.DataLoader(train_tfidf_dataset, batch_size=16, shuffle=True)\n",
        "valid_tfidf_loader = torch.utils.data.DataLoader(valid_tfidf_dataset, batch_size=16, shuffle=True)\n",
        "test_tfidf_loader = torch.utils.data.DataLoader(test_tfidf_dataset, batch_size=16, shuffle=True)\n",
        "# train_sequence_loader = torch.utils.data.DataLoader(train_seq_dataset, batch_size=16)\n",
        "# valid_sequence_loader = torch.utils.data.DataLoader(valid_seq_dataset, batch_size=16)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCDic_1lyGO2"
      },
      "source": [
        "## Running Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXtKjPMyyKIm"
      },
      "source": [
        "# Define our experimental setup; we use the same parameters for both MLP models\n",
        "input_size =  len(tfidf_vec.vocabulary_) #+ len(tfidf_vec.vocabulary_) #\n",
        "hidden_size = 200 # An arbitrary hyperparameter we define\n",
        "output_size = len(label_indexer.label2idx)\n",
        "LEARNING_RATE = 1e-2\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFFyMBsOV5nl"
      },
      "source": [
        "# To print entire confusion matrix\n",
        "import sys\n",
        "import numpy\n",
        "numpy.set_printoptions(threshold=sys.maxsize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_WGK3wxyTJO"
      },
      "source": [
        "# Model 1: MLP\n",
        "mlp = MultiLayerPerceptron(input_size, hidden_size, output_size)\n",
        "#optimizer = optim.SGD(mlp.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
        "#optimizer = optim.Adam(mlp.parameters(), lr=LEARNING_RATE)\n",
        "optimizer = optim.Adagrad(mlp.parameters(), lr=LEARNING_RATE)\n",
        "mlp_trainer = MultiClassTrainer(mlp, optimizer, loss_fn)\n",
        "mlp_trainer.run_training(train_tfidf_loader, valid_tfidf_loader, label_indexer.labels, n_epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7hKTdAYuFOz"
      },
      "source": [
        "#def evaluate(self, loader, labels):\n",
        "mlp_trainer.evaluate(test_tfidf_loader, label_indexer.labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394,
          "referenced_widgets": [
            "7d2ec216fbda4a8b888e2af8ae0e7244",
            "7b4f29eb8df1461e956f1f544820dd23",
            "e01fef8d67f641a580d03207d1d2d96f",
            "4fd5876651b54d07ab00766b2e640296",
            "2e563553408041da926f653eda2bc210",
            "0345189ae85c4bddb545653b015efbc1",
            "dc9c3c085fce4be48e54e8db3951c5d9",
            "b76ef8faa17c4c56b3f5c4bea98242c2"
          ]
        },
        "id": "hXDC2p26f-DT",
        "outputId": "3fed4fa1-aa9d-4f6d-e8c3-e3dfbca1cc53"
      },
      "source": [
        "#def evaluate(self, loader, labels):\n",
        "mlp_trainer2 = MultiClassTrainer(mlp, optimizer, loss_fn)\n",
        "mlp_trainer2.evaluate(test_tfidf_loader, label_indexer.labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d2ec216fbda4a8b888e2af8ae0e7244",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-3ce69a081a4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#def evaluate(self, loader, labels):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmlp_trainer2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiClassTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmlp_trainer2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tfidf_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_indexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-c7f00bafe358>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, loader, labels)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Disable gradient computation - required only during training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m                 \u001b[0;31m# batch[0] shape: (batch_size, input_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-79-42fe993554b8>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx_liwc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mliwc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx_liwc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-86-8323161a18bd>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(label)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlabel_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelIndexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_context_labels\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mvalid_context_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0moutput_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_indexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtrain_tfidf_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmpatheticDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_liwc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_context_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_transformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-7487ec49c533>\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    }
  ]
}